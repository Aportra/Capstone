name: Daily Scraper

on:
  workflow_dispatch:
    inputs:
      branch:
        description: 'Branch to run the workflow on'
        required: true
        default: 'main'  # Trigger on a specific branch

env:
  ACTIONS_STEP_DEBUG: true

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      # Step 1: Checkout the repository
      - name: Checkout repository
        uses: actions/checkout@v3

      # Step 2: Install Firefox 114 and Geckodriver v0.32
      - name: Install Firefox 114 and Geckodriver v0.32
        run: |
          # Install Firefox 114
          sudo apt-get update
          wget -q https://ftp.mozilla.org/pub/firefox/releases/114.0/linux-x86_64/en-US/firefox-114.0.tar.bz2
          tar -xjf firefox-114.0.tar.bz2
          sudo mv firefox /opt/firefox114
          sudo ln -sf /opt/firefox114/firefox /usr/local/bin/firefox
          rm firefox-114.0.tar.bz2

          # Install Geckodriver v0.32
          wget -q https://github.com/mozilla/geckodriver/releases/download/v0.32.0/geckodriver-v0.32.0-linux64.tar.gz
          tar -xvzf geckodriver-v0.32.0-linux64.tar.gz
          sudo mv geckodriver /usr/local/bin/
          rm geckodriver-v0.32.0-linux64.tar.gz

      # Step 3: Verify Firefox and Geckodriver Installation
      - name: Verify Firefox and Geckodriver
        run: |
          firefox --version
          geckodriver --version

      # Step 4: Set up Python
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      # Step 5: Install Python Dependencies
      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      # Step 6: Run the Scraper
      - name: Run scraper
        run: python scrape_current_nba_games.py
        env:
          SERVER_EMAIL: ${{ secrets.SERVER_EMAIL }}
          EMAIL_USERNAME: ${{ secrets.EMAIL_USERNAME }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}

      # Step 7: Upload Screenshot
      - name: Upload Screenshot
        if: always()  # Always upload the artifact even if the scraper fails
        uses: actions/upload-artifact@v3
        with:
          name: screenshots
          path: screenshot.png

      # Step 8: Upload Logs
      - name: Upload Logs
        if: always()  # Always upload logs for debugging
        uses: actions/upload-artifact@v3
        with:
          name: logs
          path: scraper.log
